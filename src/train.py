import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
import csv
import time
import datetime
from torch.utils.tensorboard import SummaryWriter

from model import UNet
from dataset import DriveDataset

# ... DiceLoss ä¿æŒä¸å˜ ...
class DiceLoss(nn.Module):
    def __init__(self):
        super(DiceLoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        intersection = (inputs * targets).sum()                            
        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  
        return 1 - dice

def train_model():
    # --- 1. åŸºç¡€é…ç½® ---
    DATA_PATH = './data/DRIVE'
    BATCH_SIZE = 32     # ã€å»ºè®®ã€‘æ˜¾å­˜å¤Ÿçš„è¯æ”¹ä¸º 32 æˆ– 64
    LEARNING_RATE = 1e-3
    EPOCHS = 100        # ã€å»ºè®®ã€‘è®¾ç½®å¤§ä¸€ç‚¹ï¼Œåæ­£æœ‰æ—©åœæœºåˆ¶ä¼šå¸®æˆ‘ä»¬åœ
    PATIENCE = 5       # ã€æ–°å¢ã€‘æ—©åœè€å¿ƒå€¼ï¼šå¦‚æœéªŒè¯é›† Loss è¿ç»­ 10 è½®ä¸ä¸‹é™ï¼Œå°±åœæ­¢
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    RESULT_DIR = os.path.join('./results', f'exp_{current_time}')
    CHECKPOINT_DIR = os.path.join(RESULT_DIR, 'checkpoints')
    LOG_CSV_PATH = os.path.join(RESULT_DIR, 'training_log.csv')
    REPORT_PATH = os.path.join(RESULT_DIR, 'final_report.txt')

    os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    with open(LOG_CSV_PATH, mode='w', newline='') as f:
        writer = csv.writer(f)
        # ä¿®æ”¹è¡¨å¤´ï¼Œå¢åŠ éªŒè¯é›†æ•°æ®
        writer.writerow(['Epoch', 'Train Loss', 'Val Loss', 'Val Dice', 'LR', 'Time(s)'])

    # --- 2. æ•°æ®åŠ è½½ ---
    # è®­ç»ƒé›†ï¼šä½¿ç”¨ training æ–‡ä»¶å¤¹å…¨éƒ¨æ•°æ®
    train_ds = DriveDataset(root_path=DATA_PATH, mode="train")
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)

    # éªŒè¯é›†ï¼šä½¿ç”¨ test æ–‡ä»¶å¤¹ä¸­çš„å‰ 5 å¼ 
    val_ds = DriveDataset(root_path=DATA_PATH, mode="val")
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)

    model = UNet(n_channels=1, n_classes=1).to(DEVICE)
    
    criterion_bce = nn.BCELoss()
    criterion_dice = DiceLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    writer = SummaryWriter(log_dir=os.path.join(RESULT_DIR, 'tensorboard_logs'))
    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ... è®¾å¤‡: {DEVICE} | Batch: {BATCH_SIZE} | Patience: {PATIENCE}")
    start_time = time.time()

    # --- æ—©åœç›¸å…³å˜é‡ ---
    best_val_loss = float('inf')
    early_stop_counter = 0  # è®¡æ•°å™¨

    # --- 3. è®­ç»ƒå¾ªç¯ ---
    for epoch in range(EPOCHS):
        epoch_start = time.time()
        
        # =========== è®­ç»ƒé˜¶æ®µ ===========
        model.train()
        train_loss = 0.0
        
        train_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]")
        for imgs, masks in train_bar:
            imgs = imgs.to(DEVICE)
            masks = masks.to(DEVICE)

            preds = model(imgs)
            preds = torch.sigmoid(preds) # ç¡®ä¿è¾“å‡ºæ˜¯ 0-1

            loss = 0.5*criterion_bce(preds, masks) + 1.5*criterion_dice(preds, masks)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_bar.set_postfix(loss=loss.item())

        avg_train_loss = train_loss / len(train_loader)

        # =========== éªŒè¯é˜¶æ®µ (æ–°å¢) ===========
        model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ (å…³é—­ Dropout ç­‰)
        val_loss = 0.0
        val_dice_score = 0.0 # è®°å½•çº¯ Dice åˆ†æ•°ç”¨äºè§‚å¯Ÿ
        
        # éªŒè¯æ—¶ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜
        with torch.no_grad():
            # è¿™é‡Œä¸ç”¨ tqdm ä¹Ÿå¯ä»¥ï¼Œé¿å…è¿›åº¦æ¡åˆ·å±
            for imgs, masks in val_loader:
                imgs = imgs.to(DEVICE)
                masks = masks.to(DEVICE)
                
                preds = model(imgs)
                preds = torch.sigmoid(preds)

                # è®¡ç®—éªŒè¯ Loss
                v_loss = criterion_bce(preds, masks) + criterion_dice(preds, masks)
                val_loss += v_loss.item()
                
                # è®¡ç®—çº¯ Dice ç³»æ•° (1 - DiceLoss) ç”¨äºäººç±»è§‚å¯Ÿ
                # æ³¨æ„ï¼šDiceLoss è¿”å›çš„æ˜¯ 1-Diceï¼Œæ‰€ä»¥æˆ‘ä»¬åæ¨ä¸€ä¸‹
                d_loss = criterion_dice(preds, masks)
                val_dice_score += (1 - d_loss.item())

        avg_val_loss = val_loss / len(val_loader)
        avg_val_dice = val_dice_score / len(val_loader)
        
        epoch_duration = time.time() - epoch_start
        current_lr = optimizer.param_groups[0]['lr']

        # --- è®°å½•ä¸æ‰“å° ---
        print(f"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Dice: {avg_val_dice:.4f}")

        # TensorBoard
        writer.add_scalar('Loss/Train', avg_train_loss, epoch)
        writer.add_scalar('Loss/Val', avg_val_loss, epoch)
        writer.add_scalar('Metric/Val_Dice', avg_val_dice, epoch)

        # CSV
        with open(LOG_CSV_PATH, mode='a', newline='') as f:
            csv.writer(f).writerow([epoch+1, f"{avg_train_loss:.4f}", f"{avg_val_loss:.4f}", f"{avg_val_dice:.4f}", current_lr, f"{epoch_duration:.2f}"])

        # =========== æ—©åœæœºåˆ¶æ ¸å¿ƒé€»è¾‘ ===========
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            early_stop_counter = 0 # é‡ç½®è®¡æ•°å™¨
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, "best_model.pth"))
            print(f"âœ… éªŒè¯é›† Loss é™ä½ï¼Œæ¨¡å‹å·²ä¿å­˜ï¼(Patience: 0/{PATIENCE})")
        else:
            early_stop_counter += 1
            print(f"âš ï¸ éªŒè¯é›† Loss æœªé™ä½ï¼Œè®¡æ•°å™¨: {early_stop_counter}/{PATIENCE}")
            
            if early_stop_counter >= PATIENCE:
                print(f"ğŸ›‘ è§¦å‘æ—©åœæœºåˆ¶ï¼è®­ç»ƒåœ¨ Epoch {epoch+1} åœæ­¢ã€‚")
                break # è·³å‡º Epoch å¾ªç¯

    # --- 4. ç»“æŸæŠ¥å‘Š ---
    total_time = str(datetime.timedelta(seconds=int(time.time() - start_time)))
    
    final_report = f"""
    Training Finished.
    Total Time: {total_time}
    Best Val Loss: {best_val_loss:.4f}
    Stopped at Epoch: {epoch+1}
    """
    with open(REPORT_PATH, "w") as f:
        f.write(final_report)
    print(final_report)
    writer.close()

if __name__ == "__main__":
    train_model()